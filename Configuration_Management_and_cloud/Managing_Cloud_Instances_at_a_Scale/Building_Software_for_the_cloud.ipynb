{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing_Data in the Cloud\n",
    "\n",
    "Cloud providers give us a lot of storage options. Picking the right solution for data storage will depend on what service you're building.\n",
    "\n",
    "When choosing a storage solution in the Cloud, you might opt to go with the traditional storage technologies, like block storage, or you can choose newer technologies, like object or blob storage. \n",
    "\n",
    "when we create a VM running in the Cloud, it has a local disk attached to it. These local disks are an example of **block storage**. This type of storage closely resembles the physical storage that you have on physical machines using physical hard drives. **Block storage in the Cloud acts almost exactly like a hard drive. The operating system of the virtual machine will create and manage a file system on top of the block storage just as if it were a physical drive.**\n",
    "\n",
    "Our block storage can be either **persistent or ephemeral**. \n",
    "\n",
    "**Persistent storage is used for instances that are long lived, and need to keep data across reboots and upgrades**. \n",
    "\n",
    "**On the flip side, ephemeral storage is used for instances that are only temporary, and only need to keep local data while they're running**. \n",
    "\n",
    "Ephemeral storage is great for temporary files that your service needs to create while it's running, but you don't need to keep. This type of storage is especially common when using containers, but it can also be useful when dealing with virtual machines that only need to store data while they're running. In typical Cloud setups, each VM has one or more disks attached to the machine.\n",
    "\n",
    "**If you're looking to share data across instances, you might want to look into some shared file system solutions, that Cloud providers offer using the platform as a service model**. \n",
    "\n",
    "**When using these solutions, the data can be accessed through network file system protocols like NFS or CIFS**. This lets you connect many different instances or containers to the same file system with no programming required. \n",
    "\n",
    "**Block storage and shared file systems work fine when you're managing servers that need to access files.**\n",
    "\n",
    "## Blob Storage\n",
    "\n",
    "**But if you're trying to deploy a Cloud app that needs to store application data, you'll probably need to look into other solutions like objects storage, which is also known as blob storage. Object storage lets you place in retrieve objects in a storage bucket**. These objects are just generic files like photos or cat videos, encoded and stored on disk as binary data. **These files are commonly called blobs, which comes from binary large object, and as we called out, these blobs are stored in locations known as buckets.**\n",
    "\n",
    "To interact with an object store, you need to use an API or special utilities that can interact with the specific object store that you're using.\n",
    "\n",
    "**Most Cloud providers offer databases as a service**. \n",
    "\n",
    "**These come in two basic flavors, SQL and NoSQL**. \n",
    "\n",
    "## SQL databases, \n",
    "\n",
    "**Are also known as relational, use the traditional database format and query language. Data is stored in tables with columns and rows that can be indexed, and we retrieve the data by writing SQL queries**. A lot of existing applications already use this model, so it's typically chosen when migrating an existing application to the Cloud. \n",
    "\n",
    "## NoSQL\n",
    "\n",
    "**NoSQL databases offer a lot of advantages related to scale. They're designed to be distributed across tons of machines and are super fast when retrieving results. But instead of a unified query language, we need to use a specific API provided by the database** . This means that we might need to rewrite the portion of the application that accesses the DB. When deciding how to store your data, you'll also have to choose a storage class. Cloud providers typically offer different classes of storage at different prices.\n",
    "\n",
    "\n",
    "### The performance of a storage solution is influenced by a number of factors, including throughput, IOPS, and latency.\n",
    "\n",
    "**Throughput is the amount of data that you can read and write in a given amount of time.\n",
    "\n",
    "**IOPS or input/output operations per second measures how many reads or writes you can do in one second, no matter how much data you're accessing. Each read or write operation has some overhead. So there's a limit on how many you can do in a given second, \n",
    "\n",
    "**latency is the amount of time it takes to complete a read or write operation.**\n",
    "\n",
    "Read latency is sometimes reported as the time it takes a storage system to start delivering data after a read request has been made, also known as **time to first byte**. While write latency is typically measured as the amount of time it takes for a write operation to complete.\n",
    "\n",
    "\n",
    "**Hot data is accessed frequently and stored in hot storage while cold data is accessed infrequently, and stored in cold storage**. These two storage types have different performance characteristics. For example, hot storage back ends are usually built using solid state disks, which are generally faster than the traditional spinning hard disks. \n",
    "\n",
    "After a year, you can move your data to cold storage where you can still get to it, but it will be slower and possibly costs more to access.\n",
    "\n",
    "\n",
    "## Load Balancing\n",
    "\n",
    "we saw a bunch of different reasons why we might want more than one machine or container running our service. For example, we might want to horizontally scale our service to handle more work, distribute instances geographically to get closer to our users. Or have backup instances to keep the service running if one or more of the instances fail. No matter the reason, we use orchestration tools and techniques to make sure that the instances are repeatable\n",
    "\n",
    "We called out earlier that this is where load balancing comes into play\n",
    "\n",
    "**A pretty common load balancing technique is round robin DNS. Round robin is a really common method for distributing tasks so that every one can get in turn**.\n",
    "\n",
    "Now, if we want to translate a URL like my service.example.com into an IP address, we use the **DNS protocol or domain name system**. In the simplest configuration, the URL always gets translated into exactly the same IP address. But when we configure our DNS to use round robin, it'll give each client asking for the translation a group of IP addresses in a different order. The clients will then pick one of the addresses to try to reach the service. If an attempt fails, the client will jump to another address on the list.\n",
    "\n",
    "This load balancing method is super easy to set up. You just need to make sure that the IPs of all machines in the pool are configured in your DNS server, **but it has some limitations**. First, you can't control which addresses get picked by the clients. Even if a server is overloaded, you can't stop the clients from reaching out to it. \n",
    "\n",
    "On top of that, DNS records are cached by the clients and other servers. So if you need to change the list of addresses for the instances, you'll have to wait until all of the DNS records that were cached by the clients expire. \n",
    "\n",
    "To have more control over how the load's distributed and to make faster changes, we can set up a server as **a dedicated load balancer. This is a machine that acts as a proxy between the clients and the servers**. It receives the requests and based on the rules that we provide, it directs them to the selected back-end server.\n",
    "\n",
    "Say your service needs to keep track of the actions that a user has taken up till now. In this case, you'll want your load balancer to use **sticky sessions**. Using sticky sessions means all requests from the same client always go to the same back end server. This can be really useful for services than need it but can also cause headaches when migrating or maintaining your service. So you need to use it only if you really need it. Otherwise, you'll end up in a really sticky situation. \n",
    "\n",
    "**Another cool feature of load balancers is that you can configure them to check the health of the backend servers**. Typically, we do this by making a simple query to the servers and checking that the reply matches the expected reply. If a back-end server is unhealthy, the load balancer will stop sending new requests to it to keep only healthy servers in the pool.\n",
    "\n",
    "If we have a load balancer controlling the load of the machines, adding a new machine to the pool is as easy as creating the instance. And then letting the load balancer know that it can now route traffic to it. **We can do this by manually creating and adding the instance or when our services under heavy load, we can just let the auto scaling feature do it**.\n",
    "\n",
    "**How do you make sure that clients connect to the servers that are closest to them? You can use Geo DNS and geoip.**\n",
    "\n",
    "**These are DNS configurations that will direct your clients to the closest geographical load balancer. The mechanism used to route the traffic relies on how the DNS servers respond to requests**.\n",
    "\n",
    "It can be tricky to set this up on your own but most Cloud providers offer it as part of their services making it much easier to have a geographically distributed service.\n",
    "\n",
    "There are some providers dedicated to bringing the contents of your services as close to the user as possible. These are the content delivery networks or **CDNs. They make up a network of physical hosts that are geographically located as close to the end user as possible.**\n",
    "\n",
    "This means that CDN servers are often in the same data center as the users Internet service provider. CDNs work by caching content super close to the user. When a user requests say, a cute cat video, it's stored in the closest CDN server. That way, when a second user in the same region requests the same cat video, it's already cached in a server that's pretty close and it can be downloaded extra fast. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
