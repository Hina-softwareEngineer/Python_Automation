{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing_Data in the Cloud\n",
    "\n",
    "Cloud providers give us a lot of storage options. Picking the right solution for data storage will depend on what service you're building.\n",
    "\n",
    "When choosing a storage solution in the Cloud, you might opt to go with the traditional storage technologies, like block storage, or you can choose newer technologies, like object or blob storage. \n",
    "\n",
    "when we create a VM running in the Cloud, it has a local disk attached to it. These local disks are an example of **block storage**. This type of storage closely resembles the physical storage that you have on physical machines using physical hard drives. **Block storage in the Cloud acts almost exactly like a hard drive. The operating system of the virtual machine will create and manage a file system on top of the block storage just as if it were a physical drive.**\n",
    "\n",
    "Our block storage can be either **persistent or ephemeral**. \n",
    "\n",
    "**Persistent storage is used for instances that are long lived, and need to keep data across reboots and upgrades**. \n",
    "\n",
    "**On the flip side, ephemeral storage is used for instances that are only temporary, and only need to keep local data while they're running**. \n",
    "\n",
    "Ephemeral storage is great for temporary files that your service needs to create while it's running, but you don't need to keep. This type of storage is especially common when using containers, but it can also be useful when dealing with virtual machines that only need to store data while they're running. In typical Cloud setups, each VM has one or more disks attached to the machine.\n",
    "\n",
    "**If you're looking to share data across instances, you might want to look into some shared file system solutions, that Cloud providers offer using the platform as a service model**. \n",
    "\n",
    "**When using these solutions, the data can be accessed through network file system protocols like NFS or CIFS**. This lets you connect many different instances or containers to the same file system with no programming required. \n",
    "\n",
    "**Block storage and shared file systems work fine when you're managing servers that need to access files.**\n",
    "\n",
    "## Blob Storage\n",
    "\n",
    "**But if you're trying to deploy a Cloud app that needs to store application data, you'll probably need to look into other solutions like objects storage, which is also known as blob storage. Object storage lets you place in retrieve objects in a storage bucket**. These objects are just generic files like photos or cat videos, encoded and stored on disk as binary data. **These files are commonly called blobs, which comes from binary large object, and as we called out, these blobs are stored in locations known as buckets.**\n",
    "\n",
    "To interact with an object store, you need to use an API or special utilities that can interact with the specific object store that you're using.\n",
    "\n",
    "**Most Cloud providers offer databases as a service**. \n",
    "\n",
    "**These come in two basic flavors, SQL and NoSQL**. \n",
    "\n",
    "## SQL databases, \n",
    "\n",
    "**Are also known as relational, use the traditional database format and query language. Data is stored in tables with columns and rows that can be indexed, and we retrieve the data by writing SQL queries**. A lot of existing applications already use this model, so it's typically chosen when migrating an existing application to the Cloud. \n",
    "\n",
    "## NoSQL\n",
    "\n",
    "**NoSQL databases offer a lot of advantages related to scale. They're designed to be distributed across tons of machines and are super fast when retrieving results. But instead of a unified query language, we need to use a specific API provided by the database** . This means that we might need to rewrite the portion of the application that accesses the DB. When deciding how to store your data, you'll also have to choose a storage class. Cloud providers typically offer different classes of storage at different prices.\n",
    "\n",
    "\n",
    "### The performance of a storage solution is influenced by a number of factors, including throughput, IOPS, and latency.\n",
    "\n",
    "**Throughput is the amount of data that you can read and write in a given amount of time.\n",
    "\n",
    "**IOPS or input/output operations per second measures how many reads or writes you can do in one second, no matter how much data you're accessing. Each read or write operation has some overhead. So there's a limit on how many you can do in a given second, \n",
    "\n",
    "**latency is the amount of time it takes to complete a read or write operation.**\n",
    "\n",
    "Read latency is sometimes reported as the time it takes a storage system to start delivering data after a read request has been made, also known as **time to first byte**. While write latency is typically measured as the amount of time it takes for a write operation to complete.\n",
    "\n",
    "\n",
    "**Hot data is accessed frequently and stored in hot storage while cold data is accessed infrequently, and stored in cold storage**. These two storage types have different performance characteristics. For example, hot storage back ends are usually built using solid state disks, which are generally faster than the traditional spinning hard disks. \n",
    "\n",
    "After a year, you can move your data to cold storage where you can still get to it, but it will be slower and possibly costs more to access.\n",
    "\n",
    "\n",
    "## Load Balancing\n",
    "\n",
    "we saw a bunch of different reasons why we might want more than one machine or container running our service. For example, we might want to horizontally scale our service to handle more work, distribute instances geographically to get closer to our users. Or have backup instances to keep the service running if one or more of the instances fail. No matter the reason, we use orchestration tools and techniques to make sure that the instances are repeatable\n",
    "\n",
    "We called out earlier that this is where load balancing comes into play\n",
    "\n",
    "**A pretty common load balancing technique is round robin DNS. Round robin is a really common method for distributing tasks so that every one can get in turn**.\n",
    "\n",
    "Now, if we want to translate a URL like my service.example.com into an IP address, we use the **DNS protocol or domain name system**. In the simplest configuration, the URL always gets translated into exactly the same IP address. But when we configure our DNS to use round robin, it'll give each client asking for the translation a group of IP addresses in a different order. The clients will then pick one of the addresses to try to reach the service. If an attempt fails, the client will jump to another address on the list.\n",
    "\n",
    "This load balancing method is super easy to set up. You just need to make sure that the IPs of all machines in the pool are configured in your DNS server, **but it has some limitations**. First, you can't control which addresses get picked by the clients. Even if a server is overloaded, you can't stop the clients from reaching out to it. \n",
    "\n",
    "On top of that, DNS records are cached by the clients and other servers. So if you need to change the list of addresses for the instances, you'll have to wait until all of the DNS records that were cached by the clients expire. \n",
    "\n",
    "To have more control over how the load's distributed and to make faster changes, we can set up a server as **a dedicated load balancer. This is a machine that acts as a proxy between the clients and the servers**. It receives the requests and based on the rules that we provide, it directs them to the selected back-end server.\n",
    "\n",
    "Say your service needs to keep track of the actions that a user has taken up till now. In this case, you'll want your load balancer to use **sticky sessions**. Using sticky sessions means all requests from the same client always go to the same back end server. This can be really useful for services than need it but can also cause headaches when migrating or maintaining your service. So you need to use it only if you really need it. Otherwise, you'll end up in a really sticky situation. \n",
    "\n",
    "**Another cool feature of load balancers is that you can configure them to check the health of the backend servers**. Typically, we do this by making a simple query to the servers and checking that the reply matches the expected reply. If a back-end server is unhealthy, the load balancer will stop sending new requests to it to keep only healthy servers in the pool.\n",
    "\n",
    "If we have a load balancer controlling the load of the machines, adding a new machine to the pool is as easy as creating the instance. And then letting the load balancer know that it can now route traffic to it. **We can do this by manually creating and adding the instance or when our services under heavy load, we can just let the auto scaling feature do it**.\n",
    "\n",
    "**How do you make sure that clients connect to the servers that are closest to them? You can use Geo DNS and geoip.**\n",
    "\n",
    "**These are DNS configurations that will direct your clients to the closest geographical load balancer. The mechanism used to route the traffic relies on how the DNS servers respond to requests**.\n",
    "\n",
    "It can be tricky to set this up on your own but most Cloud providers offer it as part of their services making it much easier to have a geographically distributed service.\n",
    "\n",
    "There are some providers dedicated to bringing the contents of your services as close to the user as possible. These are the content delivery networks or **CDNs. They make up a network of physical hosts that are geographically located as close to the end user as possible.**\n",
    "\n",
    "This means that CDN servers are often in the same data center as the users Internet service provider. CDNs work by caching content super close to the user. When a user requests say, a cute cat video, it's stored in the closest CDN server. That way, when a second user in the same region requests the same cat video, it's already cached in a server that's pretty close and it can be downloaded extra fast. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Management\n",
    "\n",
    "We can make changes in a controlled and safe way. **This is called change management, and it's what lets us keep innovating while our services keep running**. Step one in improving the safety of our changes, we have to make sure they're well-tested. **This means running unit tests and integration tests, and then running these tests whenever there's a change**. \n",
    "\n",
    "### A continuous integration system will build and test our code every time there's a change.\n",
    "\n",
    "The CI system runs even for changes that are being reviewed. That way you can catch problems before they're merged into the main branch. \n",
    "**You can use a common open source CI system like Jenkins, or if you use GitHub, you can use its Travis CI integration**. \n",
    "\n",
    "**Many cloud providers also offer continuous integration as a service**. Once the change has committed, the CI system will build and test the resulting code. \n",
    "\n",
    "**Now you can use continuous deployment, or CD, to automatically deploy the results of the build or build artifacts. Continuous deployment lets you control the deployment with rules**. For example, we usually configure our CD system to deploy new builds only when all of the tests have passed successfully.\n",
    "\n",
    "We can configure our CD to push to different environments based on some rules.when pushing puppet changes, we should have a test environment separate from the production environment.\n",
    "\n",
    "**Here environment means everything needed to run the service. It includes the machines and networks used for running the service, the deployed code, the configuration management, the application configurations, and the customer data. Production, usually shortened to prod, is the real environment, the ones users see and interact with**. \n",
    "\n",
    "You could have your CD system configured to push new changes to the test environment. You can then check that the service is still working correctly there, and then manually tell your deployment system to push those same changes to production.\n",
    "\n",
    "You might have your CD system push all new changes to a development or dev environment, then have a separate environment called pre-prod, which only gets specific changes after approval. And only after a thorough testing, these changes get pushed to pro. \n",
    "\n",
    " these environments need to be as similar to prod as possible. They should be built and deployed in the same way. And while we don't want them to be breaking all the time, it's normal for some changes to break dev or even pre-prod. We're just happy that we can catch them early so that they don't break prod. \n",
    " \n",
    " \n",
    "When you have something that you want to test in production with real customers, you can experiment using A/B testing. In A/B testing, some requests are served using one set of code and configuration, A, and other requests are served using a different set of of code and configuration, B. This is another place where a load balancer and instance groups can help us out. You can deploy one instance group in your A configuration and a second instance group in your B configuration. Then by changing the configuration of the load balancer, you can direct different percentages of inbound requests to those two configurations. If your A configuration is today's production configuration and your B configuration is something experimental, you might want to start by only directing 1 % of your requests to B.\n",
    "\n",
    "If it's hard to identify the back-end responsible for serving A requests or B requests, then much of the value of A/B testing is lost to A/B debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Limitations\n",
    "\n",
    "Using Blob Storage there might be a limit of 1,000 writes to the same blob in a given seconds. If your service performs a lot of these operations routinely, it might get blocked by these limits. In that case, you'll need to see if you can change the way you're doing the operations, for example by grouping all of the calls into one batch. Switching to a different service is sometimes an option too.\n",
    "\n",
    "Some API calls used in Cloud services can be expensive to perform, so most Cloud providers will enforce **rate limits on these calls to prevent one service from overloading the whole system**.\n",
    "\n",
    "On top of that, **there are also utilization limits, which cap the total amount of a certain resource that you can provision**. These quotas are there to help you avoid unintentionally allocating more resources than you wanted.\n",
    "\n",
    "For some of these limits, you can ask for a quota increase from the Cloud provider if you want additional capacity, and you can also set a smaller quota in the default to avoid overspending.\n",
    "\n",
    "A lot of platform as a service and infrastructure as a service offerings have costs directly related to how much they're used. They also have usage quotas. If the service you've built suddenly becomes very popular, you can run out of quota or run out of budget. By imposing a quota on an auto-scaling system, the system will grow to meet user demand until it reaches the configured limit. The trick here is to have good monitoring and alerting around behavior like this.\n",
    "\n",
    "When your service depends on a Platform as a Service offering like a hosted database or CICD system, you're handing the responsibility for maintenance and upgrades of that service off to your Cloud provider, that's great, fewer things to worry about and maintain, but it also means that you don't always get to choose what version of that software you're using. \n",
    "\n",
    "Keeping software as a service solutions up to date ensures that customers aren't vulnerable to security flaws, that bugs are promptly fixed and that new features get released early. \n",
    "\n",
    "\n",
    "you can set up a test environment for your service that uses the beta or prerelease version of a given software as a service solution, letting you test it before it impacts production.\n",
    "\n",
    "\n",
    "## More About Cloud Providers\n",
    "Here are some links to some common Quotas you’ll find in various cloud providers\n",
    "\n",
    "- https://cloud.google.com/compute/quotas#understanding_vm_cpu_and_ip_address_quotas\n",
    "- https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html\n",
    "- https://docs.microsoft.com/en-us/azure/azure-subscription-service-limits#service-specific-limits\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
