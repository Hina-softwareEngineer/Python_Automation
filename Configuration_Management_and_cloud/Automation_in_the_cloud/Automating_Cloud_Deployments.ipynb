{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Scale Deployments\n",
    "\n",
    "The biggest advantage of using **Cloud services** is how easily we can scale our services up and down.\n",
    "\n",
    "We'll set up our services so that we can easily increase their capacity by adding more nodes to the pool. These nodes could be virtual machines, containers, or even specific applications providing one service.\n",
    "\n",
    "**A load balancer ensures that each node receives a balanced number of requests. When a request comes in, the load balancer picks a node to serve the response.**\n",
    "\n",
    "There's a bunch of different strategies load balancer uses to select the node. **The simplest one is just to give each node one request called round robin**. More complex strategies include always selecting the same node for requests coming from the same origin, selecting the node that's closest to the requester, and selecting the one with the least current load.\n",
    "\n",
    "Instance groups like these are usually configured to spin up more nodes when there's more demand, and to shut some nodes down when the demand falls. **This capability is called autoscaling. It allows the service to increase or reduce capacity as needed while the service owner only pays for the cost of the machines that are in use at any given time**.\n",
    "\n",
    "\n",
    "**If you need data persistence, you'll have to create separate storage resources to hold that data and connect that storage to the nodes**. That's why the services that we run in the Cloud are usually connected to a database which is also running in the Cloud. This database will also be served by multiple nodes behind a load balancer, but this is typically managed by the Cloud provider using the platform as a service model.\n",
    "\n",
    "For large applications where speed and availability matter, there will be a couple of layers in between the entry point and the actual web service. The first layer will be a pool of web caching servers with a load balancer to distribute the requests among them. **One of the most popular applications for this caching is called Varnish, but of course it's not the only one. The Nginx web server and software also includes this caching functionality**. **There's a bunch of providers that do web caching as a service like Cloudflare and Fastly. No matter the software used, the result is basically the same.**\n",
    "\n",
    "To get any necessary data, this service will connect to a database. But because getting data from a database can be slow, **there's usually an extra layer of caching, specific for the database contents. The most popular applications for this level of caching are Memcached and Redis**.\n",
    "\n",
    "## What is Orchestration?\n",
    "\n",
    "**Automation is the process of replacing a manual step with one that happens automatically**.\n",
    "\n",
    "let us automate the creation of Cloud instances. We can use templating to create new virtual machines, we can run a command line tool that automatically creates new instances for us, or we can choose to enable auto-scaling and let the infrastructure tools take care of that depending on the demand. \n",
    "\n",
    "But all of this automatic creation of new instances needs to be coordinated so that the instances correctly interact with each other and that's where orchestration comes into play. **Orchestration is the automated configuration and coordination of complex IT systems and services. In other words, orchestration means automating a lot of different things that need to talk to each other. This will always include a lot of different automated tasks and will generally involve configuring a bunch of different systems**.\n",
    "\n",
    "**The key here is that the configuration of the overall system needs to be automatically repeatable**. There's a bunch of different tools that we can use to do that. These tools typically don't communicate with the Cloud systems through the web interface or the command line. **They normally use an application programming interface or API that lets us interact with the Cloud infrastructure directly from our scripts**\n",
    "\n",
    " In the case of Cloud provider APIs, they typically let you handle the configuration that you want to sit directly from your scripts or programs without having to call a separate command. This combines the power of programming with all of the available Cloud resources. The APIs offered by the Cloud providers let us perform all the tasks that we mentioned earlier like creating, modifying, and deleting instances and also deploying complex configurations for how these instances will talk to each other.\n",
    " \n",
    "**You wanted to deploy a system that combines some services running on a Cloud provider and some services running on-premise, this is known as a hybrid Cloud setup, or only part of the services are in the Cloud**. The setup is super common in the industry right now. \n",
    "\n",
    "**Orchestration tools can be a pretty useful tool to make sure that both the on-premise services and the Cloud services know how to talk to each other and are configured with the right settings**. \n",
    "\n",
    "Going back to the website example that we discussed earlier to make sure that the service is running smoothly, **we should set up a monitoring and alerting. This lets us detect and correct any problems with our service before users even notice. This is a critical piece of infrastructure but setting it up correctly can take quite some time**. By using orchestration tools, we can automate the configuration of any monitoring rules that we need to set, which metrics we want to look for, when we want to be alerted, and so on, and automatically apply these to a complete deployment no matter which datacenter the services are running in. \n",
    "\n",
    "## Cloud Infrastructure as Code\n",
    "\n",
    "To orchestrate complex Cloud setups. This includes handling a bunch of different nodes with different workloads, managing the complexity of deploying a hybrid setup, or modifying deployments across several Data centers.\n",
    "\n",
    "Most Cloud providers offer their own tool for managing resources as code. **Amazon has Cloud Formation, Google has Cloud Deployment Manager, Microsoft has Azure Resource Manager, and OpenStack has Heat Orchestration Templates**. \n",
    "\n",
    "These tools are specific to the Cloud provider, which means it can be complex and cumbersome to move to a different provider or combine a Cloud deployment with an on-premise deployments. **An option that's becoming really popular in the Orchestration field, is called Terraform. Similar to Puppet, Terraform uses its own Domain-specific language which lets us specify what we want our Cloud infrastructure to look like. The cool thing about Terraform is that it knows how to interact with a lot of different Cloud providers and automation vendors**. \n",
    "\n",
    "So you can write your Terraform rules to deploy something on one Cloud provider, and then use very similar rules to deploy the service to a different Cloud provider. Terraform uses each Cloud provider's API to accomplish this. This keeps you from having to learn a new API when moving to a different Cloud provider, and lets you focus on the infrastructure design. \n",
    "\n",
    "The rules that define the resources like the VMs or containers to use, will use specific values related to the Cloud provider like selecting which machine type to use or in what region to deploy it. But a lot of the overall configuration is independent of the provider, and can be reused if we decide to move our configuration to a different provider or we want to use a hybrid setup. Of course Terraform isn't the only option. Puppet itself also ships with a bunch of plug-ins that can be used to interact with the different Cloud providers to create and modify the desired Cloud infrastructure.\n",
    "\n",
    "**When dealing with nodes in the Cloud, there are basically two options. Either they're long-lived and their contents need to be periodically updated, or they are short-lived and updates are made by deleting the old instances and deploying new ones**. \n",
    "\n",
    "### Long-lived Instances\n",
    "\n",
    "Long-lived instances are typically servers that are not expected to go away. Things like your company's internal mail server or internal document sharing servers, will manage these instances using a configuration management system like Puppet, which can deploy any necessary changes to the machines while they're running. This keeps them updated to the latest state. \n",
    "\n",
    "### Short-lived Instances\n",
    "\n",
    "short-lived instances come and go very quickly. For these cases, it makes less sense to apply changes while they're running. Instead, we normally apply the configuration that we want the instances to have when they start, and we deploy any future changes by replacing the instances with new ones. We can still use Puppet for the initial setup, but we don't need to run the agent periodically, only at the start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More About Cloud & GCP\n",
    "\n",
    "Check out the following links for more information:\n",
    "\n",
    "- [Getting started on GCP with Terraform](https://cloud.google.com/community/tutorials/getting-started-on-gcp-with-terraform)\n",
    "- [Creating groups of unmanaged instances](https://cloud.google.com/compute/docs/instance-groups/creating-groups-of-unmanaged-instances)\n",
    "- Official documentation is here: https://cloud.google.com/load-balancing/docs/https/\n",
    "https://geekflare.com/gcp-load-balancer/\n",
    "\n",
    "#### Interesting articles about hybrid setups:\n",
    "\n",
    "- https://blog.inkubate.io/create-a-centos-7-terraform-template-for-vmware-vsphere/\n",
    "- https://www.terraform.io/docs/enterprise/before-installing/reference-architecture/gcp.html\n",
    "- https://www.hashicorp.com/resources/terraform-on-premises-hybrid-cloud-wayfair"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
