{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelizing Operations\n",
    "\n",
    "One way we can make this better is to do operations in **parallel**. That way, while the computer is waiting for the slow IO, other work can take place. \n",
    "\n",
    "\n",
    "The tricky part is dividing up the tasks so that we get the same result in the end. There's actually a whole field of computer science called **concurrency, dedicated to how we write programs that do operations in parallel. **\n",
    "\n",
    "When using the OS to split the work and the processes, these processes don't share any memory, and sometimes we might need to have some shared data. In that case, we'd use threads. **Threads let us run parallel tasks inside a process. This allows threads to share some of the memory with other threads in the same process.**\n",
    "\n",
    "In Python, we can use the **Threading or AsyncIO** modules to do this. These modules let us specify which parts of the code we want to run in separate threads or as separate asynchronous events, and how we want the results of each to be combined in the end.\n",
    "\n",
    "One thing to watch out for is that depending on the **actual threading implementation for the language you're using, it might happen that all threads get executed in the same CPU processor**. \n",
    "\n",
    "\n",
    "In that case, if you want to use more processors, you'll need to split the code into fully separate processes. \n",
    "\n",
    "\n",
    "**If your script is mostly just waiting on input or output, also known as I/O bound**, it might matter if it's executed on one processor or eight. But you might be doing this in parallel because you're using all of the available CPU time. In other words, your script is **CPU bound**. In this case, you'll definitely want to split your execution across processors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slowly Growing in complexity\n",
    "\n",
    "you could decide to store your data in a **SQLite file**. This is a lightweight database system that lets you query the information stored in the file without needing to run a database server. \n",
    "\n",
    "If the service becomes really really popular, you might notice that your database isn't fast enough to serve all the queries being requested. In that case, you can add a **caching service** like **memcached which keeps the most commonly used results in RAM to avoid querying the database unnecessarily**.\n",
    "\n",
    "Initially, this could just be running on a web server on the same machine as the data. If the website gets used a lot, you might need to add a **caching service like Varnish**. This would speed up the load of dynamically created pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Complex Slow Systems\n",
    "\n",
    "If the problem is not solved by indexing and there are too many queries for the server to reply to all of them on time, you might need to look into either caching the queries or distributing the data to separate database servers. \n",
    "\n",
    "But if the code is fine and the cache doesn't help because the problem is that there's just too many requests coming in for one machine to answer all of them, you'll need to distribute the load across more computers. To make this possible, you might need to reorganize the code so that it's capable of running in a distributed system instead of on a single computer. \n",
    "\n",
    "\n",
    "## Using Threads to make things Go Faster\n",
    "\n",
    "```\n",
    "    from concurrrent import futures\n",
    "\n",
    "```\n",
    "\n",
    "**Executors**\n",
    "\n",
    "To be able to run things in parallel, we'll need to create an executor. This is the process that's in charge of distributing the work among the different workers. \n",
    "\n",
    "**Futures**\n",
    "\n",
    "The futures module provides a couple of different executors, one for using threads and another for using processes. We'll go with the ThreadPoolExecutor for now.\n",
    "\n",
    "\n",
    "```\n",
    "    executor = futures.ThreadPoolExeutor()\n",
    "```\n",
    "\n",
    "Now, the function that does most of the work in this loop is process_file.\n",
    "\n",
    "Instead of calling it directly in the loop, we'll submit a new task to the executor with the name of the function and its parameters.\n",
    "\n",
    "Our for loop now creates a bunch of tasks that are all scheduled in the executor. The executor will run them in parallel using threads.\n",
    "\n",
    "An interesting thing that happens when we use threads is that the loop will finish as soon as all tasks are scheduled. But it will still take a while until the tasks complete. \n",
    "\n",
    "So we'll add a message saying that we're waiting for all threads to finish, and then call the shutdown function on the executor. This function waits until all the workers in the pool are done, and only then shuts down the executor.\n",
    "\n",
    "```\n",
    "    executor.submit(process_file, ro0t, basename)\n",
    "    print(\"waiting for threads\")\n",
    "    executor.shutdown()\n",
    "```\n",
    "\n",
    "By changing the executor to the ProcessPoolExecutor, we tell the futures module that we want to use processes instead of threads for the parallel operations.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "    executor= futures.ProcessPoolExecutor()\n",
    "\n",
    "```\n",
    "\n",
    "Wow, this is now taking less than a second to finish, and the user time has gone up even more. This is because, by using processes, we're making even more use of the CPU. The difference is caused by the way threads and processes work in Python\n",
    "\n",
    "Threads use a bunch of safety features to avoid having two threads that try to write to the same variable. And this means that when using threads, they may end up waiting for their turn to write to variables for a few milliseconds, adding up to the small difference between the two approaches.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More about Complex Systems\n",
    "\n",
    "We only touched briefly on the ways we can use concurrency to improve our programs. If you're interested in learning more, ![this article](https://realpython.com/python-concurrency/) from Real Python has a lot of details on the different ways to use concurrency in Python.\n",
    "\n",
    "\n",
    "\n",
    "Check out the following links for more information:\n",
    "\n",
    "https://realpython.com/python-concurrency/\n",
    "\n",
    "https://hackernoon.com/threaded-asynchronous-magic-and-how-to-wield-it-bba9ed602c32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
